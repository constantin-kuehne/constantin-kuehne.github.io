[
  {
    "objectID": "cv_typst.html",
    "href": "cv_typst.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Constantin Kühne\n Email |  GitHub |  LinkedIn |  Google Scholar\n\n\n\n\n\n\n\n\nEducation\nMSc Data Engineering (2023 - present)\nHasso Plattner Institute/ University of Potsdam\n\nExchange semester at Eindhoven University of Technology (2025)\nRelevant Coursework: Generative AI Models, Deep Learning, Machine Learning for Image Analysis, Reinforcement Learning & Algorithm Discovery, Knowledge Engineering, Advanced Machine Learning Seminars\n\nBSc Wirtschaftsinformatik/ Business Intelligence (2019 - 2023)\nHochschule der Bayerischen Wirtschaft\n\n\nResearch Experiences\nIcewafl: A Configurable Data Stream Polluter (11/2024 - 04/2025)\nHasso Plattner Institute\n\nResearch assistant role under Dr. Lisa Ehrlinger at the Information Systems chair of Prof. Dr. Felix Naumann\nResearch and software development on a framework for data pollution via Apache Flink [Link]\nEvaluation of the effects of data errors on machine learning models\n\nBeyond Balanced: Learning Static Search Trees with Tree-MDPs (10/2024 - 04/2025)\nHasso Plattner Institute\n\nResearch seminar under Alexander Kastius at the chair for Artificial Intelligence and Sustainability of Prof. Dr. Ralf Herbrich\nDesigned a reinforcement learning framework (Tree-MDP + A2C) to construct static binary search trees for database indexing\nAchieved up to 40% faster average lookup times on skewed query distributions vs. traditional binary search\n\nTrueSkill/MLPs Beyond Gaussians (10/2024 - 03/2025)\nHasso Plattner Institute - Master’s project under Prof. Dr. Ralf Herbrich - Research on more accurate factor graph inference via mixture models [Link]\n\n\nIndustry Experiences\nSystem Engineer (03/2023 - 08/2023)\nInfineon Technologies AG\n\nImplementation and establishment of a Customer Data Platform\nAnalysis and value creation out of customer data\n\nDual Studies at the Analytics Department (09/2019 - 03/2023)\nInfineon Technologies AG\n\nDevelopment and operationalization of software solutions in the field of Data Science\nCreation of semantic search for technical documents via Elasticsearch and language models\n\n\n\nTechnical Skills\n\n\n\n\nPython (Advanced)\nSQL (Advanced)\nJava (Intermediate)\nPyTorch (Intermediate)\nDocker (Intermediate)\nDatabricks (Intermediate)\nElasticsearch (Intermediate)\nTableau (Intermediate)\nWeights & Biases\n\n\n\n\n\n\nAwards\n\nDeutschlandstipendium, 2023-2025\n\n\n\nPublications\n\nChristoph Schinninger et al. Icewafl: A Configurable Data Stream Polluter. 2025. https://doi.org/10.48786/edbt.2025.64\n\n\n\nLanguages\n\nGerman (C2), English (C1), French (A2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Welcome to my personal website.\nI am a Master’s student in Data Engineering at the Hasso Plattner Institute, where I am dedicating my studies to the pursuit of a PhD in Computer Vision. My primary research interest lies in Computer Vision and visual understanding of the world, and my academic work is entirely focused on advancing this area of machine learning.\nMy previous research into topics like data pollution, disentangled representations learning and reinforcement learning has solidified my foundational knowledge, and I am now channeling this experience into solving the complex challenges of Computer Vision. My goal is to contribute to the development of novel models that are both theoretically innovative and practically effective.\nThis website serves as a portfolio for my academic and research activities. Here you will find my CV and details about my research projects. \nPlease feel free to connect with me via LinkedIn or explore my work on GitHub."
  },
  {
    "objectID": "projects/AI_In_Practice/AI_in_Practice__think_cell.html",
    "href": "projects/AI_In_Practice/AI_in_Practice__think_cell.html",
    "title": "Automatic Bar Detection with Decoupled Heatmap-Embedding Learning",
    "section": "",
    "text": "Project Report\n\n\n\n\nChart Object Detection with Decoupled Heatmap-Embedding Predictions\nThis repository contains a suite of models based on U-Net variants and the Swin Transformer for image segmentation. The segmentation outputs are a probability heatmap for keypoints (the top-left and bottom-right corners) of bars, as well as d channels for contrastive pixel embedding vectors used to match the keypoints of a bounding box.\nThe models are built upon the U-Net architecture and its advanced variants, using recurrent, residual and attention mechanisms to improve performance.\n\nModel Suite:\n\n\n\nBackbone Model\nResidual Skip Connections\nAttention\nRecurrent Convolutions\nDilated Convolutions\nReceptive Field\nPaper\n\n\n\n\nUNet\nNo\nNo\nNo\nNo\nSmall\nArXiV\n\n\nUNet with Local Attention (AttU_Net)\nNo\nLocal\nNo\nNo\nSmall\nArXiV\n\n\nR2U-Net\nYes\nNo\nYes\nNo\nMedium\nArXiV\n\n\nR2AttU_Net\nYes\nLocal\nYes\nNo\nMedium\n(combination of R2U_Net and AttnU_Net)\n\n\nR2AttU_Net_dilated\nYes\nLocal\nYes\nYes\nGlobal\nOurs\n\n\nUnet-like Pure Transformer (Swin-UNet)\nYes\nPatches within Shifted Windows\nNo\nNo\nGlobal\nArXiV\n\n\n\nAs backbones, we recommend models with a global receptive field (e.g. the Swin-UNet + SAM optimizer or R2AttU_Net_dilated) for learning pixel embeddings and UNet-based backbones (e.g. the R2AttU_Net performed excellent consistently) for learning the keypoint probability heatmaps.\n\n\nLosses:\n\n\n\nLoss Name\nDescription\nTask\nPaper\n\n\n\n\nCornerNet Focal Loss\n\nKeypoint Detection (Heatmap)\nArXiV\n\n\n(Vectorized) Multi Similarity Loss\n\nKeypoint Matching (Embeds)\nOurs (Adapted from ArXiV)\n\n\nPull-Push Loss\n\nKeypoint Matching (Embeds)\nArXiV\n\n\n\n\n\nDataset\nWe train, tune and evaluate our models on the bar charts “bardata(1031)” of the publically available ExcelChart400K dataset. This benchmark contains a train (158,140 images), validation (6,121 images) and test (6,262 images) split. The annotated bounding boxes are given in the COCO format (x1, y1, width, height), where a bar is defined via its top-left corner (x1,y1) and its bottom-right corner (x1+width, y1+height).\n\n\nGetting Started\nTo begin training with the default settings:\npython train.py\nOptionally you can also use the sharpness-aware minimization (SAM) optimizer to boost generalization performance (especially recommended for training the Swin-Unet, but training will take 2x as long):\npython train_with_sam.py\nTo train with custom settings, you can modify the hyperparameters defined in our training loop. We recommend setting random_augmentations=True and preprocess_images=True, as they will likely increase the model’s performance while not adding much training overhead. The train_mode (heatmaps | embeds | heatmaps_and_embeds) lets you switch the task you train the model on. Selecting heatmaps_and_embeds results in joint learning of heatmaps and embeddings with one model, which leads to better inference time at the cost of model performance. We recommend training two models to learn the heatmaps and embeds decoupled from one another. This let’s the embedding model have the heatmap as extra input for better localization of important embedding pixels and also reduces the hparams (the ms_loss_coeff for weighting the embedding vs. heatmap loss doesn’t need to be tuned).\n\n\nLogging\nThe code automatically logs train and validation losses, as well as a batch of heatmap images, similarity matrices between keypoints, and predicted bounding boxes to wandb:"
  },
  {
    "objectID": "projects/Reinforcement_Learning_For_Algorithm_Discovery/Reinforcement_Learning_and_Algorithm_Discovery.html",
    "href": "projects/Reinforcement_Learning_For_Algorithm_Discovery/Reinforcement_Learning_and_Algorithm_Discovery.html",
    "title": "Beyond Balanced: Learning Static Search Trees with Tree-MDPs",
    "section": "",
    "text": "Project Report\n\n\n\n\nNotebook\n\nBeyond Balanced: Learning Static Search Trees with Tree-MDPs\nTrain an Agent to Generate a Learned Binary Search Tree for your Query Distribution!\n\n\n\nOpen in Colab\n\n\n\nConfigure Hyperparameters for Training\n\n\nUsing device: cuda\nSetting random seed to: 42\n\n\n\n\nSelect a Query Distribution for Training\nYou can use our predefined distributions as a starting point for experimentation. We provide an abstract base class QueryDistribution in distributions.py which you can extend and customize with your own distributions for further experiments.\nIf you have a database primary key column that you would like to have optimized search for, you can try our method on your own query distribution!\n\nIf you first run this notebook, select one of the following configurations.\nA uniform distribution produces a learned tree structure that equals binary search (always splits in the middle). Non-uniform distributions produce more interesting (potentially unbalanced) optimized trees that outperform binary search with respect to the expected number of search steps.\n\n\nOptimize a Search Tree for Your Selected Query Distribution\n\n\nInitializing TreeMDP\n\n\nComputing optimal BST for Comparison (Might take a while for large arrays due to O(n^2) complexity)\nOptimal BST cost: 14782\nSaved optimal BST plot to figures/optimal_bst.pdf\nInitializing A2C agent\n\n\nStarting training for 500 episodes\n\n\nTraining finished\nPlotting training metrics\nTraining metrics saved to figures/training_metrics.pdf\n\n\nAction and policy history plotted to figures/action_policy_history.pdf\nRunning evaluation episode (greedy=True)\nObs: (0, 9), Action: 0.222, Split Idx: 2, Split Key: 2\nObs: (0, 1), Action: 0.222, Split Idx: 0, Split Key: 0\nObs: (3, 9), Action: 0.222, Split Idx: 4, Split Key: 4\nObs: (5, 9), Action: 0.222, Split Idx: 6, Split Key: 6\nObs: (7, 9), Action: 0.222, Split Idx: 7, Split Key: 7\nObs: (8, 9), Action: 0.222, Split Idx: 8, Split Key: 8\nSaved tree plot to figures/search_tree_final_greedy_eval.pdf\nFinal greedy evaluation optimality: 99.46%\nOptimality plot saved to figures/optimality.pdf\nBuilding tree with binary search\nBinary Search Tree Root Node Cost: 18426.0000\nAgent's Tree Root Node Cost: 14862.0000\nThe agent's tree is 19.34% better than standard binary search\nFigure /content/figures/optimality.pdf:\n\n\n\n\n\n\n\n\n\nFigure /content/figures/optimal_bst.pdf:\n\n\n\n\n\n\n\n\n\nFigure /content/figures/training_metrics.pdf:\n\n\n\n\n\n\n\n\n\nFigure /content/figures/action_policy_history.pdf:\n\n\n\n\n\n\n\n\n\nFigure /content/figures/query_distribution.pdf:\n\n\n\n\n\n\n\n\n\nFigure /content/figures/search_tree_final_greedy_eval.pdf:\n\n\n\n\n\n\n\n\n\nAfter running the above code, the training plots and optimized search tree are saved to the directory figures.\n\nSource: Configure Hyperparameters for Training"
  },
  {
    "objectID": "projects/Advanced_Machine_Learning_Seminar/Disentangled_Diffusion.html#abstract",
    "href": "projects/Advanced_Machine_Learning_Seminar/Disentangled_Diffusion.html#abstract",
    "title": "Learning Disentangled Representations with Identifiable Diffusion Models",
    "section": "Abstract",
    "text": "Abstract\nThis work introduces a novel framework that combines the Denoising Diffusion Probabilistic Model (DDPM) with an identifiable Variational Autoencoder (iVAE) for disentangled representation learning. Our approach leverages the strengths of diffusion models in capturing data distributions across scales and the iVAE’s capability to learn identifiable latent representations. Through extensive quantitative experimentation using various disentanglement metrics to compare our model to baseline models, and a qualitative evaluation on the Shapes3d dataset, we demonstrate our method’s ability to generate disentangled representations.\n\n[!TIP] The project uses pytorch-lightning’s CLI (link) functionality to avoid writing boilerplate code for argument parsing. \n\nThe training script for the Shapes3DVAE and Shapes3DIVAE baselines thus be ran like:\npython src/train.py \\\n --model=shapes3d.models.Shapes3DVAE \\\n --model.coeff_kl=1 \\\n --trainer.max_epochs=1\nany other arguments to either Trainer or the model classes can be provided as --model.foo=bar or --trainer.foo=bar\nTo run the training script for the combined iVAE+DDPM model (Shapes3DDisentangledDiffusionCombined), execute:\npython src/train.py \\\n --model=shapes3d.models.Shapes3DDisentangledDiffusionCombined \\\n --trainer.max_epochs=10 \\\n --model.dataset_in_memory=True \\\n --model.batch_size=32 \\\n --model.lr=2e-4 \\\n --model.grad_clip=-1 \\\n --model.coeff_rec=0.1 \\\n --model.coeff_kl=0.0005 \\\n --model.dataset_modulate_mean=false \\\n --model.plot_interpolations_at_epoch_end=true\n\nPointers to important files\nThe base models can be found under src/base/models.py. Here we created the class BaseDisentangledDiffusionCombined which combines an iVAE with a DDPM.\nWe use code from https://github.com/yang-song/score_sde under the directory src/temp_diffusion for the VPSDE in src/temp_diffusion/sde_lib.py and the layers of the DDPM in src/temp_diffusion/layers.py.\nOther important files are src/base/losses.py and src/base/layers.py where we define respectively the loss function for the DDPM and the DDPM’s layers including the conditional from the iVAE.\n\n\nGenerating samples (inference)\nTo sample images using a trained iVAE+DDPM model, you can either run model.plot_interpolations(), which creates a grid of conditional samples by interpolating each latent dimension and is also used to log images to wandb during training, or you can use the model.ancestral_sampling(batch_size=1, T=600, z=None, same_xN=False, seed=0) function that enables more control for the generations. For example, you can vary the number of diffusion time steps and pass a conditioning vector z.\n\n\nUsing other datasets\nThe model currently is trained on the shapes3d dataset. In order to use different datasets, the model can easily be adapted by defining a new base model for that dataset (refer to _BaseShapes3DModel in src/base/shapes3d) and then inheriting from that base model, i.e.:\nclass Shapes3DDisentangledDiffusionCombined(\n    _BaseShapes3DModel, base_models.BaseDisentangledDiffusionCombined\n):\n    pass"
  },
  {
    "objectID": "projects/Advanced_Machine_Learning_Seminar/Disentangled_Diffusion.html#diffusion-of-a-sample-batch-using-the-ivaeddpm",
    "href": "projects/Advanced_Machine_Learning_Seminar/Disentangled_Diffusion.html#diffusion-of-a-sample-batch-using-the-ivaeddpm",
    "title": "Learning Disentangled Representations with Identifiable Diffusion Models",
    "section": "Diffusion of a sample batch using the iVAE+DDPM",
    "text": "Diffusion of a sample batch using the iVAE+DDPM\n Each row shows one interpolated latent dimension (while all other dimensions are fixed)."
  },
  {
    "objectID": "projects/Master_Project/TrueSkill_Beyond_Gaussians.html#approximate-inference-methods-for-skill-based-ranking-and-bayesian-neural-networks",
    "href": "projects/Master_Project/TrueSkill_Beyond_Gaussians.html#approximate-inference-methods-for-skill-based-ranking-and-bayesian-neural-networks",
    "title": "TrueSkill Beyond Gaussians",
    "section": "Approximate Inference Methods for Skill-based Ranking and Bayesian Neural Networks",
    "text": "Approximate Inference Methods for Skill-based Ranking and Bayesian Neural Networks\n\n\n\nSampling MP Banner"
  },
  {
    "objectID": "projects/Master_Project/TrueSkill_Beyond_Gaussians.html#overview",
    "href": "projects/Master_Project/TrueSkill_Beyond_Gaussians.html#overview",
    "title": "TrueSkill Beyond Gaussians",
    "section": "Overview",
    "text": "Overview\nThis master project researches message passing (MP) on factor graphs by incorporating richer distributions beyond the standard Gaussian approximation. Our goal is to improve the accuracy of approximate inference in skill-based ranking (e.g., TrueSkill) and Bayesian neural networks (BNNs) by using distributions with more parameters, providing a more expressive alternative to Gaussians. Through robust updates, the estimated skills are known to improve log likelihood of observed game outcomes compared to other ranking systems such as ELO.\nWe extend TrueSkill and Bayesian Neural Networks by incorporating Mixtures of Gaussians (GMs) and Uniform Mixtures (UMs)—also known as quantile distributions or histograms—and compare their performance against the typically used Gaussians in terms of accuracy and calibration.\nOur framework is primarily implemented in Julia, which enables us to perform efficient sampling-based experiments and fast message-passing inference. This makes it possible to run large-scale probabilistic inference tasks on datasets such as historical Tennis and League of Legends matches. However, we also experimented with a Python codebase (under development), which provides a better debugging experience and higher code readability."
  },
  {
    "objectID": "projects/Master_Project/TrueSkill_Beyond_Gaussians.html#features",
    "href": "projects/Master_Project/TrueSkill_Beyond_Gaussians.html#features",
    "title": "TrueSkill Beyond Gaussians",
    "section": "Features",
    "text": "Features\n\nWe implement both slow, high-accuracy methods (e.g., Expectation Maximization) for fitting Gaussian Mixture approximations of marginals and fast, analytically derived message-passing updates for efficient inference.\nWe optimized the message computation by using segment trees for efficient multiplication and division of multiple distributions.\nWe extend TrueSkill, Linear Regression, and Bayesian Neural Networks (BNNs) to work with Gaussian Mixtures (GMs), Uniform Mixtures (UMs), and standard Gaussians.\n\n\n[!NOTE] The project’s focus was on exdending TrueSkill with more expressive distributions, so the corresponding code is more robust and validated compared to the code for Bayesian Neural Networks, which is more experimental and might not be empirically robust (e.g. for scaling the network and/ or training data size)."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nBeyond Balanced: Learning Static Search Trees with Tree-MDPs\n\n\n\nReinforcement Learning\n\nDeep Learning\n\n\n\n\n\n\n\n\n\nMay 25, 2025\n\n\nKonrad Gerlach, Till Zemann, Constantin Kühne, Hendrik Droste, Alexander Kastius, Rainer Schlosser and Ralf Herbrich\n\n\n\n\n\n\n\n\n\n\n\n\nTrueSkill Beyond Gaussians\n\n\n\nFactor Graph\n\nBayesian\n\nGaussian\n\n\n\n\n\n\n\n\n\nMar 5, 2025\n\n\nCedric Lorenz, Nick Bessin, Nina Burdorf, Till Zemann, Isabel Kurth, Lucas Kerschke, Constantin Kühne and Paul Ermler\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Disentangled Representations with Identifiable Diffusion Models\n\n\n\nComputer Vision\n\nDeep Learning\n\nRepresentation Learning\n\nDiffusion Models\n\n\n\n\n\n\n\n\n\nSep 16, 2024\n\n\nConstantin Kühne and Till Zemann\n\n\n\n\n\n\n\n\n\n\n\n\nAutomatic Bar Detection with Decoupled Heatmap-Embedding Learning\n\n\n\nComputer Vision\n\nDeep Learning\n\nContrastive Learning\n\nImage Segmentation\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nKühne, Constantin and Postnov, Kirill and Schulze Tast, Johann and Treykorn, Felix and Zemann, Till\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Email |  GitHub |  LinkedIn |  Google Scholar"
  },
  {
    "objectID": "cv.html#constantin-kühne",
    "href": "cv.html#constantin-kühne",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Email |  GitHub |  LinkedIn |  Google Scholar"
  }
]